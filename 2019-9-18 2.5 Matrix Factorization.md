# 2019-9-18 2.5 Matrix Factorization
$A \vec{x} = \vec{b}$ can be solved by $\vec{x} = A^{-1}\vec{b}$. However, finding $A^{-1}$ is somtimes really difficult.

## Triangular Matrices
### Upper Triangular
If the matrix's items $a_{i,j} = 0$ for $i > j$.

#### Examples
$$
\begin{bmatrix}
  1 & 5 & 0 \\
  0 & 2 & 4 \\
\end{bmatrix},
\begin{bmatrix}
  1 & 0 & 0 & 1 \\
  0 & 2 & 1 & 0 \\
  0 & 0 & 1 & 0 \\
  0 & 0 & 0 & 1 \\
\end{bmatrix},
\begin{bmatrix}
  2 \\ 0 \\ 0 \\ 0
\end{bmatrix}
$$

### Lower Triangular
If the matrix's items $a_{i,j} = 0$ for $i < j$.

#### Examples
$$
\begin{bmatrix}
  1 & 0 & 0 \\
  3 & 2 & 0 \\
\end{bmatrix},
\begin{bmatrix}
  3 & 0 & 0 & 0 \\
  1 & 1 & 0 & 0 \\
  0 & 0 & 1 & 0 \\
  0 & 2 & 0 & 1 \\
\end{bmatrix},
\begin{bmatrix}
  1 \\ 2 \\ 1 \\ 2
\end{bmatrix}
$$

### Diagonal Matrices
Both upper triangular and lower triangular. a.k.a. only items on the diagonal.

## LU Factorization
If $A$ is a $m \times n$ matrix that can be row reduced to echelon form **without row exchanges**, then $A = LU$ where $L$ is a lower triangular $m \times m$ matrixwith 1's on the diagonal and $U$ is an echelon form of $A$.

For example, if $A \in \mathbb{R}^{3 \times 2}$, the LU factorization has form

$$
A = LU = \begin{bmatrix}
  1 & 0 & 0 \\
  * & 1 & 0 \\
  * & * & 1 \\
\end{bmatrix}\begin{bmatrix}
  * & * \\
  0 & * \\
  0 & 0 \\
\end{bmatrix}
$$

### Why LU factorization?
Reducing $A$ to $U$ is essentially doing a bunch of row operations or applying a bunch of elementary matrices ($E_1, E_2, \dots, E_p$), which can be written as:

$$
E_p E_{p-1} \dots E_2 E_1 A = U
$$

All $E$ are lower triangular and invertible. For example:

$$
\left(\underbrace{\begin{bmatrix}
  1 & 0 & 0 \\
  0 & 1 & 0 \\
  2 & 0 & 1 \\
\end{bmatrix}}_{R_3 \leftarrow R_3 + 2R_1}\right)^{-1} = \underbrace{\begin{bmatrix}
  1 & 0 & 0 \\
  0 & 1 & 0 \\
  -2 & 0 & 1 \\
\end{bmatrix}}_{R_3 \leftarrow R_3 - 2R_1}
$$

Fliping the signs of non-diagonal items of an elementary matrix will turn it to its inverse.

Therefore, using:

$$
E_p E_{p-1} \dots E_2 E_1 A = U
$$

We can get:

$$
A = \underbrace{E_1^{-1} E_2^{-1} \dots E_{p-1}^{-1} E_p^{-1}}_{L} U = LU
$$

Also inverse will preseve lower or upper, thus L is still lower.

### Using LU Factorization to solve $\vec{x}$
Give $A$ and $\vec{b}$, solve $A\vec{x} = \vec{b}$ for $\vec{x}$

$$
A \vec{x} = \vec{b} \\
L \underbrace{U \vec{x}}_\vec{y} = \vec{b} \\
L \vec{y} = \vec{b} \\
U \vec{x} = \vec{y} \\
$$

Algorithm:

1. Forward solve for $L\vec{y} = \vec{b}$.
2. Backward solve for $U\vec{x} = \vec{y}$.

#### Example
Solve for $\vec{x}$, given:

$$
A = LU = \begin{bmatrix}
  1 & 0 & 0 & 0 \\
  1 & 1 & 0 & 0 \\
  0 & 2 & 1 & 0 \\
  0 & 0 & 1 & 1 \\
\end{bmatrix} \begin{bmatrix}
  1 & 0 & 0 \\
  0 & 2 & 1 \\
  0 & 0 & 2 \\
  0 & 0 & 0 \\
\end{bmatrix}, \vec{b} = \begin{bmatrix}
  2 \\ 3 \\ 2 \\ 0
\end{bmatrix}
$$

**Solution:**

##### Step 1. Solve for $\vec{y}$
$$
L\vec{y} = \vec{b}
$$

$$
\begin{bmatrix}
  1 & 0 & 0 & 0 \\
  1 & 1 & 0 & 0 \\
  0 & 2 & 1 & 0 \\
  0 & 0 & 1 & 1 \\
\end{bmatrix}\begin{bmatrix}
  y_1 \\ y_2 \\ y_3 \\ y_4
\end{bmatrix} = \begin{bmatrix}
  2 \\ 3 \\ 2 \\ 0
\end{bmatrix}
$$

- Row 1: $y_1 = 2$
- Row 2: $y_1 + y_2 = 3 \rightarrow y_2 = 1$
- Row 3: $2y_2 + y_3 = 2 \rightarrow y_3 = 0$
- Row 4: $y_3 + y_4 = 0 \rightarrow y_4 = 0$

$$
\vec{y} = \begin{bmatrix}
  2 \\ 1 \\ 0 \\ 0
\end{bmatrix}
$$

##### Step 2. Solve for $\vec{x}$
$$
U\vec{x} = \vec{y}
$$

$$
\begin{bmatrix}
  1 & 0 & 0 \\
  0 & 2 & 1 \\
  0 & 0 & 2 \\
  0 & 0 & 0 \\
\end{bmatrix}\begin{bmatrix}
  x_1 \\ x_2 \\ x_3
\end{bmatrix} = \begin{bmatrix}
  2 \\ 1 \\ 0 \\ 0
\end{bmatrix}
$$

- Row 3: $2x_3 = 0 \rightarrow x_3 = 0$
- Row 2: $2x_2 + x_3 = 1 \rightarrow x_2 = \frac{1}{2}$
- Row 1: $x_1 = 2$

$$
\vec{x} = \begin{bmatrix}
  2 \\ \frac{1}{2} \\ 0
\end{bmatrix}
$$

### Compute factorization of A
$$
\begin{aligned}
  A =
  &\begin{bmatrix}
    4 & -3 & -1 & 5 \\
    -16 & 12 & 2 & -17 \\
    8 & -6 & -12 & 22 \\
  \end{bmatrix}

  \\

  \xrightarrow{R_2 \leftarrow R_2 + 4R_1}
  &\begin{bmatrix}
    4 & -3 & -1 & 5 \\
    0 & 0 & -2 & 3 \\
    8 & -6 & -12 & 22 \\
  \end{bmatrix}
  & E_{2,1} = \begin{bmatrix}
    1 & 0 & 0 \\
    4 & 1 & 0 \\
    0 & 0 & 1 \\
  \end{bmatrix}

  \\

  \xrightarrow{R_3 \leftarrow R_3 - 2R_1}
  &\begin{bmatrix}
    4 & -3 & -1 & 5 \\
    0 & 0 & -2 & 3 \\
    0 & 0 & -10 & 12 \\
  \end{bmatrix}
  & E_{3,1} = \begin{bmatrix}
    1 & 0 & 0 \\
    0 & 1 & 0 \\
    -2 & 0 & 1 \\
  \end{bmatrix}

  \\

  \xrightarrow{R_3 \leftarrow R_3 -5R_2}
  &\begin{bmatrix}
    4 & -3 & -1 & 5 \\
    0 & 0 & -2 & 3 \\
    0 & 0 & 0 & -3 \\
  \end{bmatrix} = U
  & E_{3,3} = \begin{bmatrix}
    1 & 0 & 0 \\
    0 & 1 & 0 \\
    0 & -5 & 1 \\
  \end{bmatrix}
\end{aligned}
$$

$$
L = E_{2,1}^{-1} E_{3,1}^{-1} E_{3,3}^{-1} = \begin{bmatrix}
  1 & 0 & 0 \\
  -4 & 1 & 0 \\
  0 & 0 & 1 \\
\end{bmatrix} \begin{bmatrix}
  1 & 0 & 0 \\
  0 & 1 & 0 \\
  2 & 0 & 1 \\
\end{bmatrix} \begin{bmatrix}
  1 & 0 & 0 \\
  0 & 1 & 0 \\
  0 & 5 & 1 \\
\end{bmatrix} = \begin{bmatrix}
  1 & 0 & 0 \\
  -4 & 1 & 0 \\
  2 & 5 & 1 \\
\end{bmatrix}
$$

$$
A = LU = \begin{bmatrix}
  1 & 0 & 0 \\
  -4 & 1 & 0 \\
  2 & 5 & 1 \\
\end{bmatrix} \begin{bmatrix}
    4 & -3 & -1 & 5 \\
    0 & 0 & -2 & 3 \\
    0 & 0 & 0 & -3 \\
  \end{bmatrix}
$$